{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMebxdJiQ3OmPHK7j1E7WQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SharveshSp04/sxs210399-sharvesh-subapalaniraj/blob/main/q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1: Word Count Analysis - AUTO EXECUTION\n",
        "import re\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Preprocess text by converting to lowercase and removing non-alphanumeric characters\"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "def create_mock_q1_data():\n",
        "    \"\"\"Create mock text data for Q1 testing\"\"\"\n",
        "    mock_text = \"\"\"\n",
        "    frankenstein monster life frankenstein monster\n",
        "    life is good the monster in frankenstein\n",
        "    life of monster frankenstein story\n",
        "    big data spark hadoop spark data\n",
        "    hello world hello spark big data\n",
        "    frankenstein monster life data spark\n",
        "    \"\"\"\n",
        "    # Save mock data to file\n",
        "    with open(\"q1_dataset.txt\", \"w\") as f:\n",
        "        f.write(mock_text)\n",
        "    print(\"Created mock Q1 dataset\")\n",
        "\n",
        "def q1_solution():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"EXECUTING QUESTION 1\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Initialize SparkSession and SparkContext\n",
        "    spark = SparkSession.builder.appName(\"WordCount\").getOrCreate()\n",
        "    sc = spark.sparkContext\n",
        "\n",
        "    # Create mock data if real dataset doesn't exist\n",
        "    try:\n",
        "        text_rdd = sc.textFile(\"q1_dataset.txt\")\n",
        "        if text_rdd.count() == 0:\n",
        "            create_mock_q1_data()\n",
        "            text_rdd = sc.textFile(\"q1_dataset.txt\")\n",
        "    except:\n",
        "        create_mock_q1_data()\n",
        "        text_rdd = sc.textFile(\"q1_dataset.txt\")\n",
        "\n",
        "    # A. Count occurrences for each word\n",
        "    words_rdd = text_rdd.flatMap(lambda line: preprocess_text(line).split())\n",
        "    word_counts = words_rdd.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "    # Save output for part A\n",
        "    word_counts.coalesce(1).saveAsTextFile(\"q1a_word_counts_output\")\n",
        "\n",
        "    # B. Find specific words count\n",
        "    target_words = [\"frankenstein\", \"monster\", \"life\"]\n",
        "    target_words_set = set(target_words)\n",
        "\n",
        "    specific_counts = words_rdd.filter(lambda word: word in target_words_set) \\\n",
        "                              .map(lambda word: (word, 1)) \\\n",
        "                              .reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "    # Save output for part B\n",
        "    specific_counts.coalesce(1).saveAsTextFile(\"q1b_specific_words_output\")\n",
        "\n",
        "    # C. Find top 20 words with highest occurrences\n",
        "    top_20_words = word_counts.sortBy(lambda x: x[1], ascending=False).take(20)\n",
        "\n",
        "    # Convert to RDD and save\n",
        "    top_20_rdd = sc.parallelize(top_20_words)\n",
        "    top_20_rdd.coalesce(1).saveAsTextFile(\"q1c_top_20_words_output\")\n",
        "\n",
        "    # Print results for verification\n",
        "    print(\"=== Q1 Results ===\")\n",
        "    print(\"\\nA. All word counts:\")\n",
        "    for word, count in word_counts.collect():\n",
        "        print(f\"{word}: {count}\")\n",
        "\n",
        "    print(\"\\nB. Specific words count:\")\n",
        "    specific_results = specific_counts.collect()\n",
        "    for word, count in specific_results:\n",
        "        print(f\"{word}: {count}\")\n",
        "\n",
        "    print(\"\\nC. Top 20 words:\")\n",
        "    for i, (word, count) in enumerate(top_20_words, 1):\n",
        "        print(f\"{i:2d}. {word}: {count}\")\n",
        "\n",
        "    return word_counts, specific_counts, top_20_words\n",
        "\n",
        "# AUTO EXECUTE Q1\n",
        "q1_word_counts, q1_specific_counts, q1_top_20 = q1_solution()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDiO_c_dnNV8",
        "outputId": "a853f426-f53a-4861-c0da-701198fe86ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "EXECUTING QUESTION 1\n",
            "==================================================\n",
            "Created mock Q1 dataset\n",
            "=== Q1 Results ===\n",
            "\n",
            "A. All word counts:\n",
            "monster: 5\n",
            "good: 1\n",
            "of: 1\n",
            "story: 1\n",
            "big: 2\n",
            "hadoop: 1\n",
            "hello: 2\n",
            "world: 1\n",
            "frankenstein: 5\n",
            "life: 4\n",
            "is: 1\n",
            "the: 1\n",
            "in: 1\n",
            "data: 4\n",
            "spark: 4\n",
            "\n",
            "B. Specific words count:\n",
            "monster: 5\n",
            "frankenstein: 5\n",
            "life: 4\n",
            "\n",
            "C. Top 20 words:\n",
            " 1. monster: 5\n",
            " 2. frankenstein: 5\n",
            " 3. life: 4\n",
            " 4. data: 4\n",
            " 5. spark: 4\n",
            " 6. big: 2\n",
            " 7. hello: 2\n",
            " 8. good: 1\n",
            " 9. of: 1\n",
            "10. story: 1\n",
            "11. hadoop: 1\n",
            "12. world: 1\n",
            "13. is: 1\n",
            "14. the: 1\n",
            "15. in: 1\n"
          ]
        }
      ]
    }
  ]
}